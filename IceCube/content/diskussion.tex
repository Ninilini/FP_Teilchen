\section{Diskussion}
In Tabelle \ref{tab:param} sind die Qualtiätsparameter der drei Lerner zusammengefasst.
\begin{table}[ht]
    \centering
    \caption{Übersicht über die Qualitätsparameter der besten Modelle der verwendeten Lerner.}
    \label{tab:param}
    \sisetup{table-format=2.1}
    \begin{tabular} { c | c c c}
    \toprule
    {} & {Reinheit} & {Effizienz} & {AUC} \\
    \midrule
      Random-Forest  & 0.950 \pm 0.009 & 0.962 \pm 0.020 &  0.988 \pm 0.003 \\
      kNN & 0.938 \pm 0.013 & 0.949 \pm 0.024 &  0.982 \pm 0.005 \\
      Naive-Bayes & 0.840 \pm 0.016& 0.810 \pm 0.029 &  0.919 \pm 0.015 \\
    \bottomrule
    \end{tabular}
    \end{table}
    \FloatBarrier 
Alle Parameter nehmen im Idealfall den Wert 1 an.
Anhand der Werte lässt sich erkennen, dass der Random-Forest- und der kNN-Klassifikator ähnlich gute Ergebnisse liefern, während der Naive-Bayes-Lerner deutlich niedrigere Werte aufweist. Zusammenfassend lässt sich aussagen, dass alle Lerner gute Ergebnisse liefern.

Dieses lässt sich auch in den ROC-Kurven in Abbildung \ref{fig:roc} erkennen.
--------------------------warten bis Kurve repariert-------------

Des Weiteren lassen sich lediglich leichte Schwankungen der Qualitätsparameter mit Variation des Modelles erkennen. Bei Variation der Baumanzahl für den Random-Forest-Lerner bzw. der Anzahl der nächsten Nachbarn für den kNN-Lerner werden Schwankungen um unter einem Prozentpunkt beobachtet.
Anders verhält sich dieses bei der Anzahl an ausgewählten Features: Diese liefert, abhängig vom Lerner, Schwankungen um bis zu sechs Prozentpunkte. Sowohl die Verläufe, als auch die effizientesten Werte varriieren unter den Lernen.
Den stabilsten Verlauf unter Variation des Modelles liefert der Random-Forest-Lerner.

Zusammenfassend lässt sich anhand der Versuchsergebnisse aussagen, dass sich das Verwenden von Maschinellen-Lernen-Methoden sehr gut dazu eignet, um das Signal der simulierten IceCube-Daten vom Untergrund zu trennen. 
